YOLOV5_GUIDEé¡¹ç›® è¯´æ˜æ–‡æ¡£
===========================
è¯¥æ–‡æ¡£ç”¨äºè¯´æ˜yolov5_guideçš„ä½¿ç”¨ä»‹ç»ï¼Œä»¥ä¾¿èšå‡ç§‘æŠ€åŒäº‹å°†æ¥æ¶‰åŠYolov5çš„å·¥ä½œã€‚

****
	
| é¡¹ç›® | YOLOV5_GUIDE |
| ---- | ---- |
| é¡¹ç›®ç‰ˆæœ¬ | v3.0 |
| YOLOv5ç‰ˆæœ¬ | Jun 20, 2021 |
| å®Œæˆæ—¶é—´ | 2021-02-12 |


****
# ç›®å½•
* [ä¸€ã€è®­ç»ƒæ£€æµ‹éƒ¨åˆ†ï¼šå¿«é€Ÿä¸Šæ‰‹å…¥é—¨](#ä¸€ã€è®­ç»ƒæ£€æµ‹éƒ¨åˆ†ï¼šå¿«é€Ÿä¸Šæ‰‹å…¥é—¨)
* [äºŒã€æ•°æ®é›†éƒ¨åˆ†ï¼šæ•°æ®é›†ç»“æ„ã€æ‹†åˆ†ã€æ‰“æ ‡ä¸å»ºyaml](#äºŒã€æ•°æ®é›†éƒ¨åˆ†ï¼šæ•°æ®é›†ç»“æ„ã€æ‹†åˆ†ã€æ‰“æ ‡ä¸å»ºyaml)
    * 1.æ•°æ®é›†ç»“æ„
    * 2.æ‹†åˆ†æ–¹å¼
    * 3.æ‰“æ ‡æ–¹å¼
    * 4.å»ºyaml
* [ä¸‰ã€å‚æ•°éƒ¨åˆ†ï¼šæ–°æ‰‹éœ€äº†è§£çš„éƒ¨åˆ†å‚æ•°](#ä¸‰ã€å‚æ•°éƒ¨åˆ†ï¼šæ–°æ‰‹éœ€äº†è§£çš„éƒ¨åˆ†å‚æ•°)
    * 1.train
    * 2.detect
* [å››ã€YOLOv5æ–‡æ¡£](#å››ã€YOLOv5æ–‡æ¡£)
* [äº”ã€å‚è€ƒæ–‡çŒ®](#äº”ã€å‚è€ƒæ–‡çŒ®)

****


# ä¸€ã€è®­ç»ƒæ£€æµ‹éƒ¨åˆ†ï¼šå¿«é€Ÿä¸Šæ‰‹å…¥é—¨

> **Step 1: å…ˆä»windowsç¯å¢ƒç™»å½•åˆ°æœåŠ¡å™¨ï¼Œå¯ä½¿ç”¨å„ç§ç±»shellå·¥å…·æˆ–sshè½¯ä»¶ï¼Œä»¥æœ€åŸºç¡€çš„cmdä¸¾ä¾‹å¦‚ä¸‹ï¼Œè´¦æˆ·å¯†ç éœ€è¦è”ç³»æ±¤å¹³å¼€é€š**  
```bash
$ ssh xuenze@10.30.4.96
```

> **Step 2: æ–°å»ºå·¥ä½œç›®å½•ï¼Œä¾‹å¦‚test_workspaceï¼Œç„¶åè¿›å…¥å·¥ä½œç›®å½•**  
```bash
xuenze@bigdata_gpu:~$ mkdir test_workspace
xuenze@bigdata_gpu:~$ cd test_workspace
```

> **Step 3: å°†æˆ‘ä»¬çš„ç¤ºä¾‹ä»£ç cloneåˆ°æœ¬åœ°ï¼ˆå¦‚å·²cloneï¼Œå¯ä»¥è·³è¿‡ï¼‰ï¼Œç„¶åè¿›å…¥ç›®å½•**  
```bash
xuenze@bigdata_gpu:~/test_workspace$ git clone http://git.fusionfintrade.com/xuenze/yolov5_guide.git
xuenze@bigdata_gpu:~/test_workspace$ cd yolov5_guide/yolov5
```

> **Step 4: è¿›å…¥yolov5çš„å·²ç»é…ç½®å¥½çš„è™šæ‹Ÿç¯å¢ƒ**  
```bash
xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ source /home/zhuyouzhi/.bashrc
(base) xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ source activate yolov5
```

> **Step 5: è¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒç»“æŸåæ¨¡å‹ä¼šå‡ºç°åœ¨runs/train/exp/weights/best.ptï¼Œ500images+50ä¸ªepochsçš„gpuè®­ç»ƒæ—¶é—´çº¦ä¸º2-3minï¼ˆå¤šæ¬¡è®­ç»ƒåä¸ºexp2, exp3, ...è‡ªåŠ¨é€’å¢ï¼‰**  
```bash
(yolov5) xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ python3 train.py --data demo_data.yaml --epochs 50 --weights yolov5s.pt --device 0
```

> **Step 6: è¿›è¡Œæ£€æµ‹ï¼Œä½¿ç”¨æˆ‘ä»¬åˆšæ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ£€æµ‹ä½¿ç”¨æ•°æ®../demo_testä¸­çš„20å¹…å›¾ç‰‡ï¼Œç»“æœè‡ªåŠ¨å­˜æ”¾åœ¨runs/detect/exp/ä¸­ï¼ˆå¤šæ¬¡æ£€æµ‹åä¸ºexp2, exp3, ...è‡ªåŠ¨é€’å¢ï¼‰**  
```bash
(yolov5) xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ python3 detect.py --source ../demo_test --weights runs/train/exp/weights/best.pt --device 0
```

> **Step 7: é€€å‡ºè™šæ‹Ÿç¯å¢ƒ**  
```bash
(yolov5) xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ conda deactivate
(base) xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ conda deactivate
xuenze@bigdata_gpu:~/test_workspace/yolov5_guide/yolov5$ cd ~
```

# äºŒã€æ•°æ®é›†éƒ¨åˆ†ï¼šæ•°æ®é›†ç»“æ„ã€æ‹†åˆ†ã€æ‰“æ ‡ä¸å»ºyaml

## 1. æ•°æ®é›†ç»“æ„
> **ç»“æ„å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç¼–æ’ï¼Œç¤ºä¾‹å¯å‚è§ä¸€ä¸­ä½¿ç”¨çš„../demo_testã€‚ä½¿ç”¨æœ¬ç« ç¬¬3èŠ‚ä¸­çš„labelImgä¼šè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡å¯¹åº”çš„labelså†…å®¹** 
```text
\-- test123
    \-- images
        \-- train
            \-- t1.jpg
            \-- t2.jpg
            \-- ...
            \-- t1000.jpg
        \-- valid
            \-- v1.jpg
            \-- v2.jpg
            \-- ...
            \-- v1000.jpg
    \-- labels
        \-- train
            \-- classes.txt
            \-- t1.txt
            \-- t2.txt
            \-- ...
            \-- t1000.txt
        \-- valid
            \-- classes.txt
            \-- v1.txt
            \-- v2.txt
            \-- ...
            \-- v1000.txt
```
## 2. æ‹†åˆ†æ–¹å¼
> **å½“æ•°æ®é‡æ¯”è¾ƒå°æ—¶ï¼Œå¯ä»¥ä½¿ç”¨7:3(train:validation)ï¼Œæˆ–è€…6:2:2(train:validation:test)è®­ç»ƒæ•°æ®ã€‚å½“æ•°æ®é‡éå¸¸å¤§æ—¶ï¼Œå¯ä»¥ä½¿ç”¨98:1:1**


## 3. æ‰“æ ‡æ–¹å¼
> **å…ˆä¸‹è½½labelImgï¼Œå‘½ä»¤è¡Œå¯ä»¥ç›´æ¥å¯åŠ¨ï¼Œæ‰“å¼€ç›®å½•ï¼ŒçŸ©å½¢æ¡†é€‰ä¸­èŒƒå›´ï¼Œç›®æ ‡æ–‡ä»¶å¤¹ä¼šè‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„.txtå’Œclasses.txt**
```bash
$ pip install labelImg -i https://mirrors.aliyun.com/pypi/simple/
$ labelImg
```

## 4. å»ºyaml
> **æ ‡æ³¨å®Œæ•°æ®å¹¶å»ºç«‹æ•°æ®é›†ç»“æ„ä¹‹åï¼Œæœ€åä¸€æ­¥æ˜¯å»ºyamlæ–‡ä»¶ï¼Œç”¨äºè®©YOLOv5"çœ‹æ‡‚"ä½ çš„æ•°æ®é›†ç»“æ„ä¸ç›®æ ‡ã€‚è¿™é‡Œæˆ‘ä»¬ä»¥demo_dataå¯¹åº”çš„data/demo_data.yamlä¸ºä¾‹**
```yaml
# ç”¨äºæŒ‡å®štrainå’Œvalidationçš„ä¸»è·¯å¾„
# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train: ../demo_data/images/train/  # 300 images
val: ../demo_data/images/valid/  # 150 images

# ç”¨äºæŒ‡å®šç›®æ ‡ç§ç±»æ•°
# number of classes
nc: 1

# ç”¨äºæŒ‡å®šæ¯ä¸ªç›®æ ‡ç§ç±»çš„åå­—ï¼Œæ³¨æ„è¦ä¸æ‰“æ ‡ä¸­è®¾å®šçš„classes.txtä¸­çš„ç›®æ ‡åå­—ç›¸åŒï¼Œå¤šé¡¹éœ€è¦ä»¥['aa', 'bbb', 'cccc']è¿™æ ·çš„pythonæ ¼å¼ç¼–å†™
# class names
names: ['paper']
```

# ä¸‰ã€å‚æ•°éƒ¨åˆ†ï¼šæ–°æ‰‹éœ€äº†è§£çš„éƒ¨åˆ†å‚æ•°
> **ç®€å•ä»‹ç»ä¸€äº›å¸¸ç”¨å‚æ•°çš„æ„ä¹‰ï¼Œæ›´å¤šå®Œæ•´å‚æ•°è¯·å‚ç…§ç¬¬4ç« **

## 1. train
### 1.1 trainéƒ¨åˆ†å¸¸ç”¨å‚æ•°
```bash
$ python train.py --img 640 --batch 16 --epochs 5 --data test123.yaml --weights yolov5s.pt --device 0
# --img: è®¾ç½®çš„å›¾ç‰‡å¤§å°ä¸º640*640
# --batch: batch sizeï¼ˆå¦‚æœå†…å­˜ä¸è¶³åˆ™å°†å…¶è®¾å°ï¼‰
# --epochs: epochsæ¬¡æ•°è®¾å®šï¼Œå¤ªå°è®­ç»ƒé‡ä¸è¶³ï¼Œå¤ªå¤§å¯èƒ½å‘ç”Ÿè¿‡æ‹Ÿåˆç°è±¡ï¼Œä¸ªäººå»ºè®®1000ä»¥å†…è§„æ¨¡æ•°æ®é›†é€‰300-500ä¹‹é—´
# --data: ä½¿ç”¨çš„æ•°æ®é›†çš„yamlæ–‡ä»¶
# --weights: ä½¿ç”¨çš„é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼Œæœ‰yolov5s.pt, yolov5x.ptç­‰ï¼Œyolov5s.pté€Ÿåº¦æœ€å¿«
# --device: ä½¿ç”¨è®¾å¤‡ï¼Œcpuæˆ–è€…0, 1, 2,...ï¼ˆæˆ‘ä»¬æœåŠ¡å™¨ä¸­0ä¸ºgpuï¼‰
```
### 1.2 trainéƒ¨åˆ†Parseæºç 
```python
def parse_opt(known=False):
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--hyp', type=str, default='data/hyp.scratch.yaml', help='hyperparameters path')
    parser.add_argument('--epochs', type=int, default=300)
    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')
    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')
    parser.add_argument('--rect', action='store_true', help='rectangular training')
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
    parser.add_argument('--notest', action='store_true', help='only test final epoch')
    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')
    parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')
    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
    parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')
    parser.add_argument('--project', default='runs/train', help='save to project/name')
    parser.add_argument('--entity', default=None, help='W&B entity')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    parser.add_argument('--linear-lr', action='store_true', help='linear LR')
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')
    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval for W&B')
    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every "save_period" epoch')
    parser.add_argument('--artifact_alias', type=str, default="latest", help='version of dataset artifact to be used')
    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')
    opt = parser.parse_known_args()[0] if known else parser.parse_args()
    return opt
```

## 2. detect
### 2.1 detectéƒ¨åˆ†å¸¸ç”¨å‚æ•°
```bash
$ python detect.py --source test123 --weights ./yolov5s.pt --device 0
# --source: å¾…æ£€æµ‹çš„å›¾ç‰‡/ç›®å½•è·¯å¾„ï¼Œè‹¥ä¸ºç›®å½•åˆ™é€ä¸€æ£€æµ‹å…¶ä¸­æ¯ä¸€å¹…å›¾ç‰‡
# --weights: ä½¿ç”¨çš„é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼Œæœ‰yolov5s.pt, yolov5x.ptç­‰ï¼Œyolov5s.pté€Ÿåº¦æœ€å¿«
# --device: ä½¿ç”¨è®¾å¤‡ï¼Œcpuæˆ–è€…0, 1, 2,...ï¼ˆæˆ‘ä»¬æœåŠ¡å™¨ä¸­0ä¸ºgpuï¼‰
```
### 2.2 detectéƒ¨åˆ†Parseæºç 
```python
def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default='yolov5s.pt', help='model.pt path(s)')
    parser.add_argument('--source', type=str, default='data/images', help='file/dir/URL/glob, 0 for webcam')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='show results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default='runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    opt = parser.parse_args()
    return opt
```


# å››ã€YOLOv5æ–‡æ¡£
<div align="center">
<p>
<a align="left" href="https://ultralytics.com/yolov5" target="_blank">
<img width="850" src="https://github.com/ultralytics/yolov5/releases/download/v1.0/splash.jpg"></a>
</p>

<p>
YOLOv5 ğŸš€ is a family of object detection architectures and models pretrained on the COCO dataset, and represents <a href="https://ultralytics.com">Ultralytics</a>
 open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.
</p>

<!-- 
<a align="center" href="https://ultralytics.com/yolov5" target="_blank">
<img width="800" src="https://github.com/ultralytics/yolov5/releases/download/v1.0/banner-api.png"></a>
-->

</div>


## <div align="center">Documentation</div>

See the [YOLOv5 Docs](https://docs.ultralytics.com) for full documentation on training, testing and deployment.


## <div align="center">Quick Start Examples</div>


<details open>
<summary>Install</summary>

Python >= 3.6.0 required with all [requirements.txt](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) dependencies installed:
<!-- $ sudo apt update && apt install -y libgl1-mesa-glx libsm6 libxext6 libxrender-dev -->
```bash
$ git clone https://github.com/ultralytics/yolov5
$ cd yolov5
$ pip install -r requirements.txt
```
</details>

<details open>
<summary>Inference</summary>

Inference with YOLOv5 and [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36). Models automatically download from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases).

```python
import torch

# Model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5x, custom

# Images
img = 'https://ultralytics.com/images/zidane.jpg'  # or file, PIL, OpenCV, numpy, multiple

# Inference
results = model(img)

# Results
results.print()  # or .show(), .save(), .crop(), .pandas(), etc.
```

</details>



<details>
<summary>Inference with detect.py</summary>

`detect.py` runs inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases) and saving results to `runs/detect`.
```bash
$ python detect.py --source 0  # webcam
                            file.jpg  # image 
                            file.mp4  # video
                            path/  # directory
                            path/*.jpg  # glob
                            'https://youtu.be/NUsoVlDFqZg'  # YouTube video
                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```

</details>

<details>
<summary>Training</summary>

Run commands below to reproduce results on [COCO](https://github.com/ultralytics/yolov5/blob/master/data/scripts/get_coco.sh) dataset (dataset auto-downloads on first use). Training times for YOLOv5s/m/l/x are 2/4/6/8 days on a single V100 (multi-GPU times faster). Use the largest `--batch-size` your GPU allows (batch sizes shown for 16 GB devices).
```bash
$ python train.py --data coco.yaml --cfg yolov5s.yaml --weights '' --batch-size 64
                                         yolov5m                                40
                                         yolov5l                                24
                                         yolov5x                                16
```
<img width="800" src="https://user-images.githubusercontent.com/26833433/90222759-949d8800-ddc1-11ea-9fa1-1c97eed2b963.png">

</details>  

<details open>
<summary>Tutorials</summary>

* [Train Custom Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)&nbsp; ğŸš€ RECOMMENDED
* [Tips for Best Training Results](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results)&nbsp; â˜˜ï¸ RECOMMENDED
* [Weights & Biases Logging](https://github.com/ultralytics/yolov5/issues/1289)&nbsp; ğŸŒŸ NEW
* [Supervisely Ecosystem](https://github.com/ultralytics/yolov5/issues/2518)&nbsp; ğŸŒŸ NEW
* [Multi-GPU Training](https://github.com/ultralytics/yolov5/issues/475)
* [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36)&nbsp; â­ NEW
* [TorchScript, ONNX, CoreML Export](https://github.com/ultralytics/yolov5/issues/251) ğŸš€
* [Test-Time Augmentation (TTA)](https://github.com/ultralytics/yolov5/issues/303)
* [Model Ensembling](https://github.com/ultralytics/yolov5/issues/318)
* [Model Pruning/Sparsity](https://github.com/ultralytics/yolov5/issues/304)
* [Hyperparameter Evolution](https://github.com/ultralytics/yolov5/issues/607)
* [Transfer Learning with Frozen Layers](https://github.com/ultralytics/yolov5/issues/1314)&nbsp; â­ NEW
* [TensorRT Deployment](https://github.com/wang-xinyu/tensorrtx)

</details>


## <div align="center">Environments and Integrations</div>

Get started in seconds with our verified environments and integrations, including [Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_readme) for automatic YOLOv5 experiment logging. Click each icon below for details.

<div align="center">
    <a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-colab-small.png" width="15%"/>
    </a>
    <a href="https://www.kaggle.com/ultralytics/yolov5">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-kaggle-small.png" width="15%"/>
    </a>
    <a href="https://hub.docker.com/r/ultralytics/yolov5">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-docker-small.png" width="15%"/>
    </a>
    <a href="https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-aws-small.png" width="15%"/>
    </a>
    <a href="https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-gcp-small.png" width="15%"/>
    </a>
    <a href="https://wandb.ai/site?utm_campaign=repo_yolo_readme">
        <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-wb-small.png" width="15%"/>
    </a>
</div>  


## <div align="center">Compete and Win</div>

We are super excited about our first-ever Ultralytics YOLOv5 ğŸš€ EXPORT Competition with **$10,000** in cash prizes!  

<div align="center">
<a href="https://github.com/ultralytics/yolov5/discussions/3213">
    <img src="https://github.com/ultralytics/yolov5/releases/download/v1.0/banner-export-competition.png"/>
</a>
</div>


## <div align="center">Why YOLOv5</div>

<p align="center"><img width="800" src="https://user-images.githubusercontent.com/26833433/114313216-f0a5e100-9af5-11eb-8445-c682b60da2e3.png"></p>
<details>
  <summary>YOLOv5-P5 640 Figure (click to expand)</summary>
  
<p align="center"><img width="800" src="https://user-images.githubusercontent.com/26833433/114313219-f1d70e00-9af5-11eb-9973-52b1f98d321a.png"></p>
</details>
<details>
  <summary>Figure Notes (click to expand)</summary>
  
  * GPU Speed measures end-to-end time per image averaged over 5000 COCO val2017 images using a V100 GPU with batch size 32, and includes image preprocessing, PyTorch FP16 inference, postprocessing and NMS. 
  * EfficientDet data from [google/automl](https://github.com/google/automl) at batch size 8.
  * **Reproduce** by `python test.py --task study --data coco.yaml --iou 0.7 --weights yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`
</details>

### Pretrained Checkpoints

[assets]: https://github.com/ultralytics/yolov5/releases

|Model |size<br><sup>(pixels) |mAP<sup>val<br>0.5:0.95 |mAP<sup>test<br>0.5:0.95 |mAP<sup>val<br>0.5 |Speed<br><sup>V100 (ms) | |params<br><sup>(M) |FLOPs<br><sup>640 (B)
|---                    |---  |---      |---      |---      |---     |---|---   |---
|[YOLOv5s][assets]      |640  |36.7     |36.7     |55.4     |**2.0** |   |7.3   |17.0
|[YOLOv5m][assets]      |640  |44.5     |44.5     |63.1     |2.7     |   |21.4  |51.3
|[YOLOv5l][assets]      |640  |48.2     |48.2     |66.9     |3.8     |   |47.0  |115.4
|[YOLOv5x][assets]      |640  |**50.4** |**50.4** |**68.8** |6.1     |   |87.7  |218.8
|                       |     |         |         |         |        |   |      |
|[YOLOv5s6][assets]     |1280 |43.3     |43.3     |61.9     |**4.3** |   |12.7  |17.4
|[YOLOv5m6][assets]     |1280 |50.5     |50.5     |68.7     |8.4     |   |35.9  |52.4
|[YOLOv5l6][assets]     |1280 |53.4     |53.4     |71.1     |12.3    |   |77.2  |117.7
|[YOLOv5x6][assets]     |1280 |**54.4** |**54.4** |**72.0** |22.4    |   |141.8 |222.9
|                       |     |         |         |         |        |   |      |
|[YOLOv5x6][assets] TTA |1280 |**55.0** |**55.0** |**72.0** |70.8    |   |-     |-

<details>
  <summary>Table Notes (click to expand)</summary>
  
  * AP<sup>test</sup> denotes COCO [test-dev2017](http://cocodataset.org/#upload) server results, all other AP results denote val2017 accuracy.  
  * AP values are for single-model single-scale unless otherwise noted. **Reproduce mAP** by `python test.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`  
  * Speed<sub>GPU</sub> averaged over 5000 COCO val2017 images using a GCP [n1-standard-16](https://cloud.google.com/compute/docs/machine-types#n1_standard_machine_types) V100 instance, and includes FP16 inference, postprocessing and NMS. **Reproduce speed** by `python test.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45`  
  * All checkpoints are trained to 300 epochs with default settings and hyperparameters (no autoaugmentation). 
  * Test Time Augmentation ([TTA](https://github.com/ultralytics/yolov5/issues/303)) includes reflection and scale augmentation. **Reproduce TTA** by `python test.py --data coco.yaml --img 1536 --iou 0.7 --augment`
</details>


## <div align="center">Contribute</div>

We love your input! We want to make contributing to YOLOv5 as easy and transparent as possible. Please see our [Contributing Guide](CONTRIBUTING.md) to get started. 


## <div align="center">Contact</div>

For issues running YOLOv5 please visit [GitHub Issues](https://github.com/ultralytics/yolov5/issues). For business or professional support requests please visit 
[https://ultralytics.com/contact](https://ultralytics.com/contact).


# äº”ã€å‚è€ƒæ–‡çŒ®
[1. æœ¬é¡¹ç›®gitlabé“¾æ¥ï¼šhttp://git.fusionfintrade.com/xuenze/yolov5_guide](http://git.fusionfintrade.com/xuenze/yolov5_guide)

[2. YOLOv5åŸé¡¹ç›®é“¾æ¥: https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)

[3. å…¶å®ƒä¾›å‚è€ƒçš„YOLOv5æ•™ç¨‹: https://www.bilibili.com/read/cv8142756/](https://www.bilibili.com/read/cv8142756/)


